"""
Module de chargement de donn√©es pour IslandGuard
üéØ D√âVELOPP√â PAR: DEV 1

üì• INPUT: Fichiers GeoJSON, CSV
üì§ OUTPUT: DataFrame avec colonnes standardis√©es
üîó CONSOMM√â PAR: DEV 2 (resilience.py)

‚úÖ FIX: G√®re les GeoJSON SANS properties
"""

import pandas as pd
import geopandas as gpd
from pathlib import Path


def load_regions_geojson(filepath='data/mauritius_regions.geojson'):
    """
    Charge les r√©gions g√©ographiques depuis GeoJSON.
    üîß FIX: G√®re les GeoJSON sans properties (juste g√©om√©trie)
    
    Returns:
        GeoDataFrame: Avec colonnes:
            - region_id (str) - G√âN√âR√â si absent
            - region_name (str) - G√âN√âR√â si absent
            - geometry (Polygon/MultiPolygon)
    """
    try:
        gdf = gpd.read_file(filepath)
        
        print(f"‚úÖ GeoJSON charg√©: {len(gdf)} features")
        print(f"   Colonnes: {gdf.columns.tolist()}")
        
        # ============================================
        # FIX: V√©rifier si properties existent
        # ============================================
        
        # Si PAS de region_id ‚Üí CR√âER automatiquement
        if 'region_id' not in gdf.columns:
            print("   ‚ö†Ô∏è Aucun region_id trouv√© ‚Üí G√©n√©ration automatique")
            
            # Cr√©er IDs temporaires bas√©s sur l'INDEX
            gdf['region_id'] = [f"TEMP_{i:02d}" for i in range(len(gdf))]
            gdf['region_name'] = [f"R√©gion {i+1}" for i in range(len(gdf))]
            
            print(f"   ‚úÖ {len(gdf)} IDs g√©n√©r√©s: TEMP_00, TEMP_01, ...")
        
        # Si region_id existe mais pas region_name
        elif 'region_name' not in gdf.columns:
            gdf['region_name'] = gdf['region_id']
            print("   ‚úÖ region_name cr√©√© depuis region_id")
        
        # V√©rifier geometry
        if gdf.geometry.isnull().any():
            print(f"   ‚ö†Ô∏è {gdf.geometry.isnull().sum()} g√©om√©tries nulles supprim√©es")
            gdf = gdf[~gdf.geometry.isnull()]
        
        # Simplifier g√©om√©tries pour performance
        print("   üîÑ Simplification g√©om√©tries...")
        gdf['geometry'] = gdf['geometry'].simplify(tolerance=0.001, preserve_topology=True)
        
        print(f"   ‚úÖ {len(gdf)} r√©gions pr√™tes")
        
        return gdf
    
    except FileNotFoundError:
        print(f"‚ùå Fichier introuvable: {filepath}")
        return gpd.GeoDataFrame()
    
    except Exception as e:
        print(f"‚ùå Erreur chargement GeoJSON: {e}")
        import traceback
        traceback.print_exc()
        return gpd.GeoDataFrame()


def load_resilience_data(filepath='data/resilience_scores.csv'):
    """
    Charge les donn√©es de r√©silience (E, V, A).
    
    Returns:
        DataFrame: Avec colonnes:
            - region_id (str)
            - region_name (str)
            - exposure (float 0-100)
            - vulnerability (float 0-100)
            - adaptation (float 0-100)
    """
    try:
        df = pd.read_csv(filepath, low_memory=False)
        
        print(f"‚úÖ CSV charg√©: {len(df)} lignes")
        print(f"   Colonnes: {df.columns.tolist()}")
        
        # V√©rifier colonnes obligatoires
        required = ['region_id', 'exposure', 'vulnerability', 'adaptation']
        missing = [col for col in required if col not in df.columns]
        
        if missing:
            raise ValueError(f"‚ùå Colonnes manquantes: {missing}")
        
        # Ajouter region_name si absent
        if 'region_name' not in df.columns:
            df['region_name'] = df['region_id']
            print("   ‚ö†Ô∏è region_name cr√©√© depuis region_id")
        
        # Convertir en num√©rique
        for col in ['exposure', 'vulnerability', 'adaptation']:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # Supprimer NaN
        before = len(df)
        df = df.dropna(subset=['exposure', 'vulnerability', 'adaptation'])
        if len(df) < before:
            print(f"   ‚ö†Ô∏è {before - len(df)} lignes avec NaN supprim√©es")
        
        # Clip valeurs 0-100
        for col in ['exposure', 'vulnerability', 'adaptation']:
            df[col] = df[col].clip(0, 100)
        
        print(f"   ‚úÖ {len(df)} r√©gions valides")
        
        return df
    
    except FileNotFoundError:
        print(f"‚ùå Fichier introuvable: {filepath}")
        return pd.DataFrame()
    
    except Exception as e:
        print(f"‚ùå Erreur chargement CSV: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()


def merge_data():
    """
    üéØ FONCTION D'INT√âGRATION COMPL√àTE
    
    üîß FIX PRINCIPAL:
    Si GeoJSON n'a pas de region_id ‚Üí on merge par ORDRE (index)
    
    Returns:
        GeoDataFrame: Donn√©es compl√®tes
    """
    print("\nüîÑ FUSION DES DONN√âES...")
    
    # 1. Charger g√©om√©trie
    regions_gdf = load_regions_geojson('data/mauritius_regions.geojson')
    if len(regions_gdf) == 0:
        print("‚ùå Impossible de continuer sans r√©gions")
        return gpd.GeoDataFrame()
    
    # 2. Charger donn√©es r√©silience
    resilience_df = load_resilience_data('data/resilience_scores.csv')
    if len(resilience_df) == 0:
        print("‚ùå Impossible de continuer sans donn√©es r√©silience")
        return gpd.GeoDataFrame()
    
    # ============================================
    # üîß FIX: MERGE INTELLIGENT
    # ============================================
    
    # V√©rifier si GeoJSON a des IDs temporaires
    if regions_gdf['region_id'].iloc[0].startswith('TEMP_'):
        print("\n‚ö†Ô∏è GeoJSON sans IDs r√©els d√©tect√©")
        print("   üîÑ MERGE PAR ORDRE (index)")
        
        # V√©rifier que les longueurs correspondent
        if len(regions_gdf) != len(resilience_df):
            print(f"   ‚ùå ERREUR: {len(regions_gdf)} g√©om√©tries ‚â† {len(resilience_df)} donn√©es CSV")
            print("   ‚ö†Ô∏è On prend seulement les correspondances possibles")
            
            # Prendre le minimum
            n = min(len(regions_gdf), len(resilience_df))
            regions_gdf = regions_gdf.head(n)
            resilience_df = resilience_df.head(n)
        
        # MERGE PAR INDEX
        # R√©initialiser les index
        regions_gdf = regions_gdf.reset_index(drop=True)
        resilience_df = resilience_df.reset_index(drop=True)
        
        # Copier les vraies donn√©es du CSV dans le GeoDataFrame
        regions_gdf['region_id'] = resilience_df['region_id'].values
        regions_gdf['region_name'] = resilience_df['region_name'].values
        regions_gdf['exposure'] = resilience_df['exposure'].values
        regions_gdf['vulnerability'] = resilience_df['vulnerability'].values
        regions_gdf['adaptation'] = resilience_df['adaptation'].values
        
        # Ajouter population si pr√©sente
        if 'population' in resilience_df.columns:
            regions_gdf['population'] = resilience_df['population'].values
        else:
            # Population par d√©faut
            regions_gdf['population'] = 50000
        
        merged_gdf = regions_gdf
        
        print(f"   ‚úÖ {len(merged_gdf)} r√©gions fusionn√©es par INDEX")
    
    else:
        # MERGE NORMAL par region_id
        print("\nüîÑ MERGE NORMAL par region_id")
        
        # Normaliser IDs
        regions_gdf['region_id'] = regions_gdf['region_id'].astype(str).str.strip().str.upper()
        resilience_df['region_id'] = resilience_df['region_id'].astype(str).str.strip().str.upper()
        
        # Merge
        merged_gdf = regions_gdf.merge(
            resilience_df,
            on='region_id',
            how='inner',
            suffixes=('_geo', '_data')
        )
        
        # G√©rer les colonnes dupliqu√©es
        if 'region_name_data' in merged_gdf.columns:
            merged_gdf['region_name'] = merged_gdf['region_name_data']
            merged_gdf = merged_gdf.drop(columns=['region_name_geo', 'region_name_data'])
        
        # Ajouter population si absente
        if 'population' not in merged_gdf.columns:
            merged_gdf['population'] = 50000
        
        print(f"   ‚úÖ {len(merged_gdf)} r√©gions fusionn√©es")
        
        # V√©rifier pertes
        lost_geom = len(regions_gdf) - len(merged_gdf)
        lost_data = len(resilience_df) - len(merged_gdf)
        
        if lost_geom > 0:
            print(f"   ‚ö†Ô∏è {lost_geom} g√©om√©tries sans donn√©es (ignor√©es)")
        if lost_data > 0:
            print(f"   ‚ö†Ô∏è {lost_data} donn√©es sans g√©om√©trie (ignor√©es)")
    
    # V√©rification finale
    print(f"\n‚úÖ FUSION TERMIN√âE: {len(merged_gdf)} r√©gions")
    print(f"   Colonnes: {merged_gdf.columns.tolist()}")
    
    # V√©rifier colonnes essentielles
    required = ['region_id', 'region_name', 'geometry', 'exposure', 'vulnerability', 'adaptation']
    missing = [col for col in required if col not in merged_gdf.columns]
    
    if missing:
        print(f"   ‚ùå ERREUR: Colonnes manquantes: {missing}")
    else:
        print(f"   ‚úÖ Toutes les colonnes requises pr√©sentes")
    
    return merged_gdf


def load_hazard_zones(filepath='data/mock/hazard_zones.geojson'):
    """Charge zones de danger (optionnel)"""
    try:
        gdf = gpd.read_file(filepath)
        print(f"‚úÖ {len(gdf)} zones de danger charg√©es")
        return gdf
    except:
        return gpd.GeoDataFrame()


# TESTS
if __name__ == "__main__":
    print("=" * 60)
    print("üß™ TESTS DATA LOADER (VERSION FIX√âE)")
    print("=" * 60)
    
    # Test fusion
    df = merge_data()
    
    if len(df) > 0:
        print("\nüìä R√âSULTAT FINAL:")
        print(df[['region_id', 'region_name', 'exposure', 'vulnerability', 'adaptation']].head(10))
        
        print(f"\n‚úÖ {len(df)} r√©gions pr√™tes pour l'app!")
    else:
        print("\n‚ùå √âchec du chargement")
    
    print("\n" + "=" * 60)